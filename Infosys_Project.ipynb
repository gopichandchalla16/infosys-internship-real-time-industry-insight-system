{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gopichandchalla16/infosys-internship-real-time-industry-insight-system/blob/anshika-dev/Infosys_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Infosys Springboard Internship ‚Äî Sprint 1\n",
        "\n",
        "**Purpose:** notebook that fetches market & news data, synthesizes/ingests tweet-like text, runs sentiment analysis (FinBERT + lightweight fallback), and visualizes sentiment vs price trends.\n",
        "\n",
        "**Team Members:**<br>\n",
        "Anshika Gupta<br>\n",
        "Gopichand<br>\n",
        "Janmejay Singh<br>\n",
        "Vaishnavi<br>\n",
        "\n",
        "<!-- Colab badge: opens this notebook in Google Colab -->\n",
        "<a href=\"https://colab.research.google.com/github/gopichandchalla16/infosys-internship-real-time-industry-insight-system/blob/main/Project_Sprint1.ipynb\" target=\"_blank\">\n",
        "  <img alt=\"Open In Colab\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"/>\n",
        "</a>\n",
        "\n",
        "**Quick run**\n",
        "- **In Google Colab**: click the badge above and run the notebook cells in order (or: `Runtime ‚Üí Run all`).\n",
        "\n",
        "**Required environment variables / API keys**\n",
        "- `ALPHA_VANTAGE_API` ‚Äî Alpha Vantage API key (for market prices).\n",
        "- Optional: `SLACK_WEBHOOK_URL` ‚Äî (for Slack alerts).\n",
        "Set these either as environment variables or (in Colab) via `google.colab.userdata.set()`.\n",
        "\n",
        "**Notes & warnings**\n",
        "- The notebook may download large models (e.g., `ProsusAI/finbert`). This can be slow on CPU and will use significant bandwidth and disk space. A GPU runtime is **recommended** for FinBERT inference.\n"
      ],
      "metadata": {
        "id": "6Sw-QMuyzasG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Overview\n",
        "\n",
        "This notebook is developed as part of the **Infosys Springboard Internship ** and demonstrates a complete **financial sentiment analysis pipeline** using real-world market and news data.\n",
        "\n",
        "### üîπ What this notebook does\n",
        "1. Accepts a **company name** as user input.\n",
        "2. Fetches:\n",
        "   - **Stock market data** from Alpha Vantage / Yahoo Finance\n",
        "   - **News articles** from Google News RSS\n",
        "   - **Company description** from Wikipedia\n",
        "3. Collects or generates **tweet-style financial text**.\n",
        "4. Performs **sentiment analysis** using:\n",
        "   - ‚úÖ `ProsusAI/finbert` (finance-specific transformer model)\n",
        "   - ‚úÖ Lightweight NLP fallback (TextBlob)\n",
        "5. Produces:\n",
        "   - üìä Sentiment distribution plots\n",
        "   - üìà Price vs sentiment trend analysis\n",
        "6. Sends **Slack alerts** based on detected sentiment.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Key Outputs Generated\n",
        "- Processed tweet sentiment (`positive`, `neutral`, `negative`)\n",
        "- Market trend graph\n",
        "- Sentiment trend visualization\n",
        "- Slack notification\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö†Ô∏è Reproducibility Notes\n",
        "- Internet access is required.\n",
        "- API keys must be configured before execution.\n",
        "- Some models require high memory and may run slow on CPU-only systems.\n",
        "\n"
      ],
      "metadata": {
        "id": "4P6CNxhfzexC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# USER INPUT (RESTRICTED TO PREDEFINED LIST)\n",
        "# =========================\n",
        "\n",
        "ALLOWED_COMPANIES = {\n",
        "    \"NETFLIX\",\n",
        "    \"APPLE\",\n",
        "    \"TESLA\",\n",
        "    \"GOOGLE\",\n",
        "    \"MICROSOFT\",\n",
        "    \"TCS\",\n",
        "    \"INFOSYS\",\n",
        "    \"RAKUTEN\",\n",
        "    \"BITCOIN\",\n",
        "    \"AMAZON\",\n",
        "    \"META\",\n",
        "    \"NVIDIA\",\n",
        "    \"AMD\",\n",
        "    \"INTEL\",\n",
        "    \"JP MORGAN\",\n",
        "    \"GOLDMAN SACHS\",\n",
        "    \"MASTERCARD\",\n",
        "    \"VISA\",\n",
        "    \"RELIANCE\",\n",
        "    \"HDFC\",\n",
        "    \"ICICI\",\n",
        "    \"WIPRO\",\n",
        "    \"HCL\",\n",
        "    \"ADANIPORTS\",\n",
        "    \"ADANIENT\",\n",
        "    \"TATA MOTORS\",\n",
        "    \"MARUTI\",\n",
        "    \"COCA COLA\",\n",
        "    \"PEPSICO\",\n",
        "    \"WALMART\",\n",
        "    \"ETHEREUM\",\n",
        "    \"DOGECOIN\",\n",
        "    \"SOLANA\"\n",
        "}\n",
        "\n",
        "def get_valid_company_name():\n",
        "    \"\"\"\n",
        "    Restricts user input strictly to a predefined list of companies.\n",
        "    Ignores case and extra spaces.\n",
        "\n",
        "    Returns:\n",
        "        str: Validated company name\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"‚úÖ Please select a company ONLY from the list below:\\n\")\n",
        "    for name in (ALLOWED_COMPANIES):\n",
        "        print(\"‚Ä¢\", name)\n",
        "\n",
        "    print(\"\\n--------------------------------------\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Enter company name exactly as shown above: \").strip().upper()\n",
        "\n",
        "        # ‚ùå Empty input\n",
        "        if not user_input:\n",
        "            print(\"‚ùå Input cannot be empty. Please select from the provided list.\")\n",
        "            continue\n",
        "\n",
        "        # ‚ùå Invalid company\n",
        "        if user_input not in ALLOWED_COMPANIES:\n",
        "            print(\"‚ùå Invalid selection. Please select from the provided list only.\")\n",
        "            continue\n",
        "\n",
        "        return user_input.title()\n",
        "\n",
        "\n",
        "# Collect validated input\n",
        "company_name = get_valid_company_name()\n",
        "\n",
        "print(f\"\\n‚úÖ Selected company for analysis: {company_name}\")\n"
      ],
      "metadata": {
        "id": "4YyUXUB29i_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Step 2: Import Required Libraries\n",
        "We use the following Python libraries:\n",
        "- `requests` & `BeautifulSoup` for scraping web data\n",
        "- `pandas` for data manipulation\n",
        "- `matplotlib` & `seaborn` for visualization\n",
        "- `textblob` for sentiment analysis\n",
        "- `yfinance` for market data\n",
        "- `wikipedia` for Wikipedia summaries\n"
      ],
      "metadata": {
        "id": "xxg1COmrz7bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SAFE PACKAGE INSTALLATION & VERIFICATION\n",
        "# =========================\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib\n",
        "\n",
        "REQUIRED_PACKAGES = [\n",
        "    \"transformers\",\n",
        "    \"torch\",\n",
        "    \"yfinance\",\n",
        "    \"alpha-vantage\",\n",
        "    \"textblob\",\n",
        "    \"feedparser\",\n",
        "    \"beautifulsoup4\",\n",
        "    \"faker\",\n",
        "    \"pandas\",\n",
        "    \"numpy\",\n",
        "    \"matplotlib\",\n",
        "    \"wikipedia\",\n",
        "    \"requests\"\n",
        "]\n",
        "\n",
        "def install_if_missing(package):\n",
        "    try:\n",
        "        importlib.import_module(package.replace(\"-\", \"_\"))\n",
        "        print(f\"‚úÖ {package} already installed\")\n",
        "    except ImportError:\n",
        "        print(f\"‚è≥ Installing {package} ...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "# Install all required packages\n",
        "for pkg in REQUIRED_PACKAGES:\n",
        "    install_if_missing(pkg)\n",
        "\n",
        "print(\"\\n‚úÖ Package installation complete.\")\n",
        "\n",
        "\n",
        "# üî• Hardware & Runtime Warning\n",
        "try:\n",
        "    import torch\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"‚ö†Ô∏è GPU not detected. FinBERT will run slowly on CPU.\")\n",
        "    else:\n",
        "        print(\"‚úÖ GPU detected. FinBERT will run efficiently.\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Torch not loaded yet. GPU detection skipped.\")\n"
      ],
      "metadata": {
        "id": "5jjXfzcR-2Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìò Company Overview Retrieval (Wikipedia)\n",
        "\n",
        "This section retrieves a **brief public overview of the selected company** using the official Wikipedia API. This provides:\n",
        "\n",
        "- ‚úÖ Business background\n",
        "- ‚úÖ Industry context\n",
        "- ‚úÖ General understanding before data analysis\n",
        "- ‚úÖ Human-readable description for reports and dashboards  \n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Why this step is important\n",
        "- Helps users understand **what entity is being analyzed**\n",
        "- Adds **context to sentiment and market trends**\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ What this cell does\n",
        "- Queries Wikipedia using the validated `company_name`\n",
        "- Automatically resolves:\n",
        "  - Page disambiguation (e.g., multiple meanings of the same name)\n",
        "  - Missing pages\n",
        "  - Network failures\n",
        "- Limits the output to a **short readable summary**\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö†Ô∏è Failure Handling & Reliability\n",
        "This cell is designed to **never crash the notebook** even if:\n",
        "- The company page does not exist\n",
        "- Multiple Wikipedia pages match\n",
        "- Internet access is unavailable  \n",
        "In all cases, a meaningful fallback message is returned.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Output\n",
        "A short textual description of the selected company or asset that will be displayed to the user before market and sentiment analysis begins.\n"
      ],
      "metadata": {
        "id": "7y-ChCrN0I7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# ROBUST WIKIPEDIA COMPANY OVERVIEW FETCH\n",
        "# =========================\n",
        "\n",
        "import wikipedia\n",
        "\n",
        "\n",
        "def _generate_variants(name):\n",
        "    variants = [\n",
        "        name,\n",
        "        f\"{name} Inc.\",\n",
        "        f\"{name}, Inc.\",\n",
        "        f\"{name} Corporation\",\n",
        "        f\"{name} Company\",\n",
        "        f\"{name} Ltd.\",\n",
        "        f\"{name} (company)\",\n",
        "        f\"{name} (company)\",\n",
        "        f\"{name} (film)\",\n",
        "        f\"{name} (cryptocurrency)\"\n",
        "    ]\n",
        "\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for v in variants:\n",
        "        if v.lower() not in seen:\n",
        "            seen.add(v.lower())\n",
        "            out.append(v)\n",
        "    return out\n",
        "\n",
        "def fetch_wikipedia_summary(company_name, max_sentences=10):\n",
        "    \"\"\"\n",
        "    Robustly fetch a short Wikipedia summary for a company/asset.\n",
        "    Tries: direct lookup, wikipedia.search suggestions, common name variants,\n",
        "    and gracefully handles disambiguation/page/network errors.\n",
        "\n",
        "    Returns:\n",
        "        str: Short summary or informative fallback message.\n",
        "    \"\"\"\n",
        "    # 1) Try direct summary first (fast path)\n",
        "    try:\n",
        "        return wikipedia.summary(company_name, sentences=max_sentences)\n",
        "    except wikipedia.exceptions.DisambiguationError as e:\n",
        "        # Will fall through to search-based resolution below\n",
        "        pass\n",
        "    except wikipedia.exceptions.PageError:\n",
        "        pass\n",
        "    except Exception:\n",
        "        # Network or unexpected failure ‚Äî we'll try search but keep fallback\n",
        "        pass\n",
        "\n",
        "    # 2) Try searching for likely titles\n",
        "    try:\n",
        "        search_results = wikipedia.search(company_name, results=8)\n",
        "    except Exception:\n",
        "        search_results = []\n",
        "\n",
        "    # 3) If search returned candidates, pick the best (first) candidate and fetch summary\n",
        "    for candidate in search_results:\n",
        "        try:\n",
        "            # Avoid picking obviously irrelevant short matches (like single letters)\n",
        "            if len(candidate) < 2:\n",
        "                continue\n",
        "            summary = wikipedia.summary(candidate, sentences=max_sentences)\n",
        "            return summary\n",
        "        except wikipedia.exceptions.DisambiguationError:\n",
        "            # If candidate is ambiguous, try the first option from its disambiguation\n",
        "            try:\n",
        "                dis_opt = wikipedia.search(candidate, results=1)\n",
        "                if dis_opt:\n",
        "                    summary = wikipedia.summary(dis_opt[0], sentences=max_sentences)\n",
        "                    return summary\n",
        "            except Exception:\n",
        "                continue\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    # 4) Try helpful title variants (Inc., Ltd., Corporation, etc.)\n",
        "    for variant in _generate_variants(company_name):\n",
        "        try:\n",
        "            summary = wikipedia.summary(variant, sentences=max_sentences)\n",
        "            return summary\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    # 5) Final fallback\n",
        "    return (f\"‚ö†Ô∏è Could not reliably fetch a Wikipedia summary for '{company_name}'. \"\n",
        "            \"This may be due to ambiguous names or missing pages. \")\n",
        "\n",
        "# Usage: get the summary and print it\n",
        "wiki_summary = fetch_wikipedia_summary(company_name)\n",
        "print(\"\\nüìò Company Overview (Wikipedia):\\n\")\n",
        "print(wiki_summary)\n"
      ],
      "metadata": {
        "id": "zpuF0W1uBFQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Market Data Retrieval (Stocks & Crypto)\n",
        "\n",
        "This section retrieves **historical price data** for the selected company or cryptocurrency.\n",
        "\n",
        "\n",
        "### üîπ What this cell does\n",
        "- Automatically detects and fetches:\n",
        "  - **Stock market data** (e.g., Tesla, Apple, Reliance)\n",
        "  - **Cryptocurrency data** (e.g., Bitcoin, Ethereum)\n",
        "- Uses **Yahoo Finance (`yfinance`)** as the primary data source\n",
        "- Fetches:\n",
        "  - Daily closing prices\n",
        "  - Date-wise time-series data for the last few months\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Why this step is important\n",
        "- Provides the **numerical basis** for:\n",
        "  - Trend analysis\n",
        "  - Graph plotting\n",
        "  - Market movement interpretation\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö†Ô∏è Failure Handling & Reliability\n",
        "This cell is designed to **fail safely without stopping the notebook** if:\n",
        "- The ticker symbol is invalid\n",
        "- Internet connection is unavailable\n",
        "- The API does not return data\n",
        "- The selected asset is delisted or inactive\n",
        "\n",
        "In such cases:\n",
        "- A warning message is printed\n",
        "- An empty DataFrame is returned\n",
        "- Downstream plotting is automatically skipped\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Output\n",
        "- A validated DataFrame with:\n",
        "  - `Date`\n",
        "  - `Open`\n",
        "  - `High`\n",
        "  - `Low`\n",
        "  - `Volume`\n",
        "  - `Close`\n",
        "\n",
        "This structured output is passed directly to the visualization and analysis stages.\n"
      ],
      "metadata": {
        "id": "KDXuaRLm05Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SAFE MARKET DATA FETCH (STOCKS + CRYPTO)\n",
        "# =========================\n",
        "\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "\n",
        "tickers = {\n",
        "    \"NETFLIX\": \"NFLX\",\n",
        "    \"APPLE\": \"AAPL\",\n",
        "    \"TESLA\": \"TSLA\",\n",
        "    \"GOOGLE\": \"GOOGL\",\n",
        "    \"MICROSOFT\": \"MSFT\",\n",
        "    \"TCS\": \"TCS.NS\",\n",
        "    \"INFOSYS\": \"INFY.NS\",\n",
        "    \"RAKUTEN\": \"RKUNY\",\n",
        "    \"BITCOIN\": \"BTC-USD\",\n",
        "    \"AMAZON\": \"AMZN\",\n",
        "    \"META\": \"META\",\n",
        "    \"NVIDIA\": \"NVDA\",\n",
        "    \"AMD\": \"AMD\",\n",
        "    \"INTEL\": \"INTC\",\n",
        "    \"JP MORGAN\": \"JPM\",\n",
        "    \"GOLDMAN SACHS\": \"GS\",\n",
        "    \"MASTERCARD\": \"MA\",\n",
        "    \"VISA\": \"V\",\n",
        "    \"RELIANCE\": \"RELIANCE.NS\",\n",
        "    \"HDFC\": \"HDFCBANK.NS\",\n",
        "    \"ICICI\": \"ICICIBANK.NS\",\n",
        "    \"WIPRO\": \"WIPRO.NS\",\n",
        "    \"HCL\": \"HCLTECH.NS\",\n",
        "    \"ADANIPORTS\": \"ADANIPORTS.NS\",\n",
        "    \"ADANIENT\": \"ADANIENT.NS\",\n",
        "    \"TATA MOTORS\": \"TATAMOTORS.NS\",\n",
        "    \"MARUTI\": \"MARUTI.NS\",\n",
        "    \"TESLA\": \"TSLA\",\n",
        "    \"COCA COLA\": \"KO\",\n",
        "    \"PEPSICO\": \"PEP\",\n",
        "    \"WALMART\": \"WMT\",\n",
        "    \"NETFLIX\": \"NFLX\",\n",
        "    \"ETHEREUM\": \"ETH-USD\",\n",
        "    \"DOGECOIN\": \"DOGE-USD\",\n",
        "    \"SOLANA\": \"SOL-USD\"\n",
        "}\n",
        "\n",
        "def fetch_market_data(asset_name, period=\"1mo\", interval=\"1d\"):\n",
        "    \"\"\"\n",
        "    Safely fetches historical market data for stocks and crypto.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with Date and Close price, or empty DataFrame on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        asset_name = tickers.get(company_name.upper(), company_name.upper())\n",
        "        ticker = yf.Ticker(asset_name)\n",
        "        market_data = ticker.history(period=period, interval=interval)\n",
        "\n",
        "        if market_data is None or market_data.empty:\n",
        "            print(f\"‚ö†Ô∏è No market data found for: {asset_name}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        market_data = market_data.reset_index()\n",
        "\n",
        "        if \"Close\" not in market_data.columns:\n",
        "            print(f\"‚ö†Ô∏è 'Close' price column missing for: {asset_name}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        return market_data[['Date','Open','High','Low','Close','Volume']]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Market data fetch failed for {asset_name}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "# Fetch data using validated company selection\n",
        "market_df = fetch_market_data(company_name)\n",
        "\n",
        "# Final validation before proceeding\n",
        "if market_df.empty:\n",
        "    print(\"‚ùå Market data unavailable. Downstream trend analysis will be skipped.\")\n",
        "else:\n",
        "    print(\"‚úÖ Market data successfully retrieved!\")\n",
        "    display(market_df.head())\n"
      ],
      "metadata": {
        "id": "mHKKSF6dCprF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì∞ News Data Collection\n",
        "\n",
        "This cell fetches the **latest news related to the selected company/asset** using Google News RSS feeds.  \n",
        "The extracted headlines are later used for **sentiment analysis**.\n"
      ],
      "metadata": {
        "id": "PZxX4mt8FubZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# SAFE NEWS FETCH WITH LINKS (GOOGLE NEWS RSS)\n",
        "# =========================\n",
        "\n",
        "import feedparser\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Removes HTML tags and extra spaces.\"\"\"\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "\n",
        "def fetch_company_news_with_links(company_name, max_articles=10):\n",
        "    \"\"\"\n",
        "    Safely fetches latest news headlines and links for a given company using Google News RSS.\n",
        "\n",
        "    Returns:\n",
        "        list of dictionaries with 'title' and 'link'\n",
        "    \"\"\"\n",
        "    try:\n",
        "        query = company_name.replace(\" \", \"+\")\n",
        "        rss_url = f\"https://news.google.com/rss/search?q={query}\"\n",
        "\n",
        "        feed = feedparser.parse(rss_url)\n",
        "\n",
        "        if not feed.entries:\n",
        "            print(\"‚ö†Ô∏è No news articles found.\")\n",
        "            return []\n",
        "\n",
        "        news_list = []\n",
        "        seen_titles = set()\n",
        "\n",
        "        for entry in feed.entries[:max_articles]:\n",
        "            title = clean_text(entry.title)\n",
        "            link = entry.link\n",
        "\n",
        "            # Avoid duplicate titles\n",
        "            if title.lower() not in seen_titles:\n",
        "                seen_titles.add(title.lower())\n",
        "                news_list.append({\"title\": title, \"link\": link})\n",
        "\n",
        "        return news_list\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"‚ö†Ô∏è News fetch failed:\", e)\n",
        "        return []\n",
        "\n",
        "\n",
        "\n",
        "news_articles_with_links = fetch_company_news_with_links(company_name)\n",
        "\n",
        "print(f\"\\nüì∞ Total News Articles Fetched: {len(news_articles_with_links)}\\n\")\n",
        "\n",
        "if news_articles_with_links:\n",
        "    for i, article in enumerate(news_articles_with_links, 1):\n",
        "        print(f\"{i}. {article['title']}\")\n",
        "        print(f\"   ‚Üí Link: {article['link']}\\n\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No news data available.\")\n"
      ],
      "metadata": {
        "id": "68Mu90I5G_aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name=company_name.replace(\" \", \"\");\n",
        "rss_url = f\"https://news.google.com/rss/search?q={name}&hl=en-US&gl=US&ceid=US:en\"\n",
        "global news_items\n",
        "feed = feedparser.parse(rss_url)\n",
        "news_items = [{\"Title\": entry.title, \"Published\": entry.published} for entry in feed.entries[:10]]\n",
        "titles = [item[\"Title\"] for item in news_items]\n",
        "news_df = pd.DataFrame(news_items)\n",
        "print(f\"\\n Top 10 News Headlines for {company_name}:\")\n",
        "display(news_df)"
      ],
      "metadata": {
        "id": "eO47yejsKe2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üòä Sentiment Analysis on News Headlines\n",
        "\n",
        "This cell performs **sentiment analysis only on the fetched news headlines** using a pre-trained NLP model.  \n",
        "Each headline is classified as **Positive, Negative, or Neutral** and later aggregated to determine the overall market mood.\n"
      ],
      "metadata": {
        "id": "q19M7i6cJ3wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "fake = Faker()\n",
        "# ------------------------\n",
        "# Select text source safely\n",
        "# ------------------------\n",
        "if news_items:\n",
        "    texts = [item[\"Title\"] for item in news_items]\n",
        "    source_type = \"news\"\n",
        "else:\n",
        "    texts = [fake.sentence(nb_words=6) for _ in range(10)]\n",
        "    source_type = \"tweets\"\n",
        "\n",
        "# ------------------------\n",
        "# Sentiment phrases\n",
        "# ------------------------\n",
        "positive_phrases = [\n",
        "    f\"{company_name} is surging!\",\n",
        "    f\"Profits from {company_name} are amazing!\",\n",
        "    f\"Holding {company_name} long-term, confident.\",\n",
        "    f\"{company_name} adoption is growing worldwide!\",\n",
        "    f\"Investors are optimistic about {company_name}.\"\n",
        "]\n",
        "\n",
        "negative_phrases = [\n",
        "    f\"Worried about {company_name} volatility.\",\n",
        "    f\"{company_name} might crash soon.\",\n",
        "    f\"{company_name}'s future is uncertain.\",\n",
        "    f\"High risks in {company_name} investments.\",\n",
        "    f\"{company_name} energy consumption is concerning.\"\n",
        "]\n",
        "\n",
        "neutral_phrases = [\n",
        "    f\"{company_name} price remains stable today.\",\n",
        "    f\"Market watching {company_name} closely.\",\n",
        "    f\"{company_name} updates coming soon.\",\n",
        "    f\"{company_name} performance unchanged.\",\n",
        "    f\"Analysts report on {company_name} today.\"\n",
        "]\n",
        "\n",
        "# ------------------------\n",
        "# Generate sentiment data\n",
        "# ------------------------\n",
        "sentiment_texts = []\n",
        "for text in texts:\n",
        "    sentiment_choice = random.choices(\n",
        "        [\"positive\", \"negative\", \"neutral\"], weights=[0.4, 0.3, 0.3]\n",
        "    )[0]\n",
        "\n",
        "    if sentiment_choice == \"positive\":\n",
        "        sentiment_texts.append(random.choice(positive_phrases))\n",
        "    elif sentiment_choice == \"negative\":\n",
        "        sentiment_texts.append(random.choice(negative_phrases))\n",
        "    else:\n",
        "        sentiment_texts.append(random.choice(neutral_phrases))\n",
        "\n",
        "sentiment_df = pd.DataFrame(sentiment_texts, columns=[\"Text\"])\n",
        "\n",
        "# ------------------------\n",
        "# Display output based on source\n",
        "# ------------------------\n",
        "if source_type == \"news\":\n",
        "    print(f\"\\nPerforming sentiment analysis on {len(texts)} news items:\\n\")\n",
        "    for i, t in enumerate(texts, 1):\n",
        "        print(f\"{i}. {t}\")\n",
        "else:\n",
        "    print(f\"\\nPerforming sentiment analysis on {len(texts)} generated tweets:\\n\")\n",
        "    display(sentiment_df)\n"
      ],
      "metadata": {
        "id": "5CMBXYPkNgA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import math\n",
        "\n",
        "\n",
        "try:\n",
        "    finbert_analyzer = pipeline(\"sentiment-analysis\", model=\"yiyanghkust/finbert-tone\", tokenizer=\"yiyanghkust/finbert-tone\")\n",
        "    print(\"‚úÖ FinBERT model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Failed to load FinBERT model:\", e)\n",
        "    finbert_analyzer = None\n",
        "\n",
        "\n",
        "def chunk_text(text, max_words=200):\n",
        "    \"\"\"\n",
        "    Break text into chunks for FinBERT analysis\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), max_words):\n",
        "        chunks.append(\" \".join(words[i:i+max_words]))\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def analyze_full_news_sentiment(news_list):\n",
        "    \"\"\"\n",
        "    Performs sentiment analysis on full news content (not just titles).\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    if not news_list:\n",
        "        print(\"‚ö†Ô∏è No news available for sentiment analysis.\")\n",
        "        return results\n",
        "\n",
        "    if finbert_analyzer is None:\n",
        "        print(\"‚ùå FinBERT model not available.\")\n",
        "        return results\n",
        "\n",
        "    for article in news_list:\n",
        "        try:\n",
        "            chunks = chunk_text(article, max_words=200)\n",
        "            chunk_results = [finbert_analyzer(chunk)[0] for chunk in chunks]\n",
        "\n",
        "            # Aggregate sentiments\n",
        "            sentiment_counts = {\"positive\": 0, \"neutral\": 0, \"negative\": 0}\n",
        "            confidence_sum = {\"positive\": 0, \"neutral\": 0, \"negative\": 0}\n",
        "\n",
        "            for res in chunk_results:\n",
        "                label = res[\"label\"].lower()\n",
        "                sentiment_counts[label] += 1\n",
        "                confidence_sum[label] += res[\"score\"]\n",
        "\n",
        "            # Choose the sentiment with highest total confidence\n",
        "            final_sentiment = max(confidence_sum, key=confidence_sum.get)\n",
        "            final_confidence = round(confidence_sum[final_sentiment] / max(sentiment_counts[final_sentiment], 1), 4)\n",
        "\n",
        "            results.append({\n",
        "                \"text\": article,\n",
        "                \"sentiment\": final_sentiment,\n",
        "                \"confidence\": final_confidence\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Failed to analyze:\", article[:50], \"...\")\n",
        "            print(\"Reason:\", e)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Example usage\n",
        "# news_articles = [\"Full text of financial news article 1\", \"Full text of article 2 ...\"]\n",
        "deep_sentiments = analyze_full_news_sentiment(texts)\n",
        "\n",
        "for i, item in enumerate(deep_sentiments, 1):\n",
        "    print(f\"\\n{i}. {item['text'][:100]}...\")\n",
        "    print(f\"   ‚Üí Sentiment: {item['sentiment']}\")\n",
        "    print(f\"   ‚Üí Confidence: {item['confidence']}\")\n"
      ],
      "metadata": {
        "id": "Rw3d4hozdHHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Sentiment Distribution Visualization\n",
        "\n",
        "This section displays a bar chart representing the distribution of sentiment categories across the analyzed news articles.\n",
        "\n",
        "### Purpose\n",
        "To provide a quick visual summary of how sentiments (positive, neutral, negative) are distributed for the selected company.\n",
        "\n",
        "### Method\n",
        "- Sentiment labels are counted using a frequency-based approach.\n",
        "- The results are visualized using a bar chart.\n",
        "\n",
        "### Output\n",
        "A bar graph showing the number of articles per sentiment category.\n"
      ],
      "metadata": {
        "id": "nusu1skoGdBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# Count sentiments\n",
        "sentiment_labels = [item[\"sentiment\"] for item in deep_sentiments]\n",
        "sentiment_counts = Counter(sentiment_labels)\n",
        "\n",
        "# Prepare data\n",
        "labels = list(sentiment_counts.keys())\n",
        "values = list(sentiment_counts.values())\n",
        "\n",
        "# Plot bar chart\n",
        "plt.figure()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.2)\n",
        "plt.bar(labels, values)\n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.ylabel(\"Number of Articles\")\n",
        "plt.title(f\"Sentiment Analysis Distribution for {company_name}\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5keHdvuw1Lnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìà Sentiment Polarity Trend\n",
        "\n",
        "This visualization shows how sentiment polarity changes across a sequence of analyzed articles.\n",
        "\n",
        "### Purpose\n",
        "To represent the direction and strength of sentiments over time using a continuous trend.\n",
        "\n",
        "### Method\n",
        "- Positive sentiments are plotted above zero.\n",
        "- Negative sentiments are plotted below zero.\n",
        "- Neutral sentiments remain at zero.\n",
        "- Confidence scores determine the magnitude of polarity.\n",
        "\n",
        "### Output\n",
        "A line chart displaying sentiment polarity across the selected articles.\n"
      ],
      "metadata": {
        "id": "7RADOrxbGpaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_sentiment_polarity(deep_sentiments, max_points=10):\n",
        "    \"\"\"\n",
        "    Plots a line chart of sentiment polarity.\n",
        "    Positive -> above 0\n",
        "    Negative -> below 0\n",
        "    Neutral  -> on 0\n",
        "    \"\"\"\n",
        "\n",
        "    # Limit to first 10 sentiments\n",
        "    sentiments = deep_sentiments[:max_points]\n",
        "\n",
        "    x_values = list(range(1, len(sentiments) + 1))\n",
        "    y_values = []\n",
        "\n",
        "    for item in sentiments:\n",
        "        sentiment = item[\"sentiment\"].lower()\n",
        "        confidence = item[\"confidence\"]\n",
        "\n",
        "        if sentiment == \"positive\":\n",
        "            y_values.append(confidence)\n",
        "        elif sentiment == \"negative\":\n",
        "            y_values.append(-confidence)\n",
        "        else:  # neutral\n",
        "            y_values.append(0)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure()\n",
        "    plt.plot(x_values, y_values, marker='o')\n",
        "\n",
        "    plt.xlabel(\"Sentiment Order\")\n",
        "    plt.ylabel(\"Polarity Score\")\n",
        "    plt.title(\"Sentiment Polarity\")\n",
        "\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_sentiment_polarity(deep_sentiments)\n"
      ],
      "metadata": {
        "id": "B__Dk68X1PAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Closing Price Trend (Last 30 Days)\n",
        "\n",
        "Plots the company's closing prices over the last 30 days. Dates are formatted as \"MM-DD\" for readability. To reduce clutter, only every 3rd date is shown on the x-axis.\n"
      ],
      "metadata": {
        "id": "qu7HFSiHJZMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dates to \"Month-Day\" format\n",
        "market_df[\"Date_str\"] = market_df[\"Date\"].dt.strftime('%m-%d')\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(market_df[\"Date_str\"], market_df[\"Close\"], marker='o', color='orange')\n",
        "plt.title(f\"{company_name} Closing Price Trend (Last 30 Days)\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Price (USD)\")\n",
        "plt.grid(True)\n",
        "\n",
        "N = 3  # fewer labels\n",
        "plt.xticks(ticks=range(0, len(market_df), N), labels=market_df[\"Date_str\"][::N])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8xGqBkK91Trl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Alpha Vantage for Stock Data\n",
        "\n",
        "\n",
        "First, install the library:"
      ],
      "metadata": {
        "id": "iZ_alNKg-aa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install alpha_vantage"
      ],
      "metadata": {
        "id": "7bX0mwDa-cXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìà Stock & Crypto Trend Analysis (Alpha Vantage)\n",
        "\n",
        "This cell fetches daily market data using the Alpha Vantage API, automatically detects stock or crypto symbols from company names, and analyzes market trends using 20-day and 50-day Simple Moving Averages (SMA). It then classifies the asset as **Bullish**, **Bearish**, or **Sideways** based on SMA crossover logic.\n"
      ],
      "metadata": {
        "id": "mg6caA7--6My"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from alpha_vantage.timeseries import TimeSeries\n",
        "import pandas as pd\n",
        "from google.colab import userdata\n",
        "\n",
        "API_KEY = userdata.get('ALPHA_VANTAGE_API')\n",
        "def detect_symbol(company_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Maps common company/asset names to their typical stock or crypto symbols.\n",
        "    If no match is found, the name itself is returned as the potential symbol.\n",
        "    \"\"\"\n",
        "    mapping = {\n",
        "    \"BITCOIN\": \"BTCUSD\",\n",
        "    \"BTC\": \"BTCUSD\",\n",
        "    \"TESLA\": \"TSLA\",\n",
        "    \"TSLA\": \"TSLA\",\n",
        "    \"NETFLIX\": \"NFLX\",\n",
        "    \"NFLX\": \"NFLX\",\n",
        "    \"INFOSYS\": \"INFY\",\n",
        "    \"INFY\": \"INFY\",\n",
        "    \"TCS\": \"TCS\",\n",
        "    \"TATA CONSULTANCY\": \"TCS\",\n",
        "    \"RAKUTEN\": \"RKUNY\",\n",
        "    \"APPLE\": \"AAPL\",\n",
        "    \"AAPL\": \"AAPL\",\n",
        "    \"GOOGLE\": \"GOOG\",\n",
        "    \"ALPHABET\": \"GOOG\",\n",
        "    \"GOOG\": \"GOOG\",\n",
        "    \"MICROSOFT\": \"MSFT\",\n",
        "    \"MSFT\": \"MSFT\",\n",
        "    \"AMAZON\": \"AMZN\",\n",
        "    \"AMZN\": \"AMZN\",\n",
        "    \"NVIDIA\": \"NVDA\",\n",
        "    \"NVDA\": \"NVDA\",\n",
        "    \"META\": \"META\",\n",
        "    \"FACEBOOK\": \"META\",\n",
        "    \"AMD\": \"AMD\",\n",
        "    \"INTEL\": \"INTC\",\n",
        "    \"COCA COLA\": \"KO\",\n",
        "    \"PEPSICO\": \"PEP\",\n",
        "    \"WALMART\": \"WMT\",\n",
        "    \"RELIANCE\": \"RELIANCE.BSE\",\n",
        "    \"HDFC\": \"HDFC.BSE\",\n",
        "    \"ICICI\": \"ICICIBANK.BSE\",\n",
        "    \"WIPRO\": \"WIPRO.BSE\",\n",
        "    \"HCL\": \"HCLTECH.BSE\",\n",
        "    \"ETHEREUM\": \"ETHUSD\",\n",
        "    \"ETH\": \"ETHUSD\",\n",
        "    \"DOGE\": \"DOGEUSD\",\n",
        "    \"DOGECOIN\": \"DOGEUSD\",\n",
        "    \"SOLANA\": \"SOLUSD\",\n",
        "    \"SOL\": \"SOLUSD\",\n",
        "}\n",
        "\n",
        "    return mapping.get(company_name.upper(), company_name.upper())\n",
        "\n",
        "    # --- Core Trend Analysis Logic ---\n",
        "def get_trend(df: pd.DataFrame) -> tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Calculates 20-day and 50-day Simple Moving Averages (SMA) to determine\n",
        "    the market trend (Bullish, Bearish, or Sideways).\n",
        "    The '4. close' column is used for calculations.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "\n",
        "    # Check for minimum data requirement for a reliable 50-day SMA\n",
        "    if len(df) < 50:\n",
        "        return \"‚ö†Ô∏è Insufficient Data\", \"Cannot calculate trend (needs at least 50 days of data)\"\n",
        "\n",
        "    # Calculate SMAs\n",
        "    df['SMA20'] = df['4. close'].rolling(window=20).mean()\n",
        "    df['SMA50'] = df['4. close'].rolling(window=50).mean()\n",
        "\n",
        "    latest = df.iloc[-1]\n",
        "\n",
        "    # Handle potential NaN values (occurs if the window is not yet full)\n",
        "    if pd.isna(latest['SMA20']) or pd.isna(latest['SMA50']):\n",
        "         return \"‚ö†Ô∏è Data Not Yet Complete\", \"Need more data points for rolling average calculation\"\n",
        "\n",
        "    # Compare SMAs (Golden Cross / Death Cross strategy)\n",
        "    if latest['SMA20'] > latest['SMA50']:\n",
        "        return \"‚úÖ Bullish Trend\", \"The short-term trend (SMA20) is above the long-term trend (SMA50). Potential Uptrend.\"\n",
        "    elif latest['SMA20'] < latest['SMA50']:\n",
        "        return \"‚ùå Bearish Trend\", \"The short-term trend (SMA20) is below the long-term trend (SMA50). Potential Downtrend.\"\n",
        "    else:\n",
        "        return \"‚ÜîÔ∏è Sideways Market\", \"SMAs are crossing or are too close. Neutral ‚Äî Wait for a breakout.\"\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "def run_analysis():\n",
        "    \"\"\"\n",
        "    Main function to ask for user input, fetch data, and print the analysis.\n",
        "    \"\"\"\n",
        "    if not API_KEY:\n",
        "        print(\"\\n‚ùå Error: ALPHA_VANTAGE_API_KEY is not configured.\")\n",
        "        print(\"Please set the 'ALPHA_VANTAGE_API_KEY' secret in your environment.\")\n",
        "        return\n",
        "\n",
        "    if not company_name:\n",
        "        print(\"Analysis cancelled: Company name cannot be empty.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nData analysis will be performed for: {company_name}\")\n",
        "\n",
        "    # --- SYMBOL DETECTION ---\n",
        "    global symbol\n",
        "    symbol = detect_symbol(company_name)\n",
        "    print(f\"Using symbol: {symbol}\")\n",
        "\n",
        "    # --- FETCH & PROCESS ---\n",
        "    try:\n",
        "        # Initialize the TimeSeries client\n",
        "        ts = TimeSeries(key=API_KEY, output_format='pandas')\n",
        "        global data\n",
        "        # Fetch daily data (compact size fetches 100 data points, good for 50-day SMA)\n",
        "        data, meta = ts.get_daily(symbol=symbol, outputsize='compact')\n",
        "        # Alpha Vantage returns data newest-first, so sort the index (date) oldest-first\n",
        "        data = data.sort_index()\n",
        "        # print(data)\n",
        "\n",
        "        print(f\"\\nüìä Latest Market Data for {company_name} ({symbol}):\")\n",
        "        # Display the last 3 days of data for review\n",
        "        print(data[['4. close']].tail(3).to_markdown(numalign=\"left\", stralign=\"left\"))\n",
        "        global trend, decision\n",
        "        # Perform the trend analysis\n",
        "        trend, decision = get_trend(data)\n",
        "\n",
        "        # Output the results\n",
        "        print(\"\\n--- Analysis Result ---\")\n",
        "        print(f\"Asset: {company_name} ({symbol})\")\n",
        "        print(f\"üìå Trend Status: {trend}\")\n",
        "        print(f\"üßæ Decision: {decision}\")\n",
        "        print(\"-----------------------\")\n",
        "\n",
        "    except ValueError as ve:\n",
        "        # Alpha Vantage throws ValueError on invalid symbol or API key issues\n",
        "        print(f\"\\n‚ùå Error fetching data for {company_name} ({symbol}):\")\n",
        "        print(f\"    Details: {ve}\")\n",
        "        print(\"    Suggestion: Check if the symbol is correct and if the API key is valid.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå An unexpected error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_analysis()"
      ],
      "metadata": {
        "id": "WKMLPJAv_2nM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's visualize the closing price over time:\n",
        "\n"
      ],
      "metadata": {
        "id": "2zoIvXLfCfU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure data exists\n",
        "if 'data' in locals() and hasattr(data, \"empty\") and not data.empty:\n",
        "\n",
        "    # Ensure index is datetime for proper plotting\n",
        "    if not isinstance(data.index, type(pd.to_datetime([]))):\n",
        "        data.index = pd.to_datetime(data.index, errors='coerce')\n",
        "\n",
        "    # Sort by date just in case\n",
        "    data = data.sort_index()\n",
        "\n",
        "    # Ensure required column exists\n",
        "    if '4. close' in data.columns:\n",
        "\n",
        "        # Drop NaN values to avoid broken lines\n",
        "        plot_data = data['4. close'].dropna()\n",
        "\n",
        "        plt.figure(figsize=(12,6))\n",
        "        plt.plot(plot_data.index, plot_data, label='Closing Price', linewidth=2)\n",
        "\n",
        "        plt.title(f\"{company_name} ({symbol}) - Closing Price Over Time\", fontsize=14)\n",
        "        plt.xlabel(\"Date\", fontsize=12)\n",
        "        plt.ylabel(\"Closing Price (USD)\", fontsize=12)\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        print(\"Column '4. close' not found in data.\")\n",
        "else:\n",
        "    print(\"No data available to visualize. Please run the data fetch cell first.\")\n"
      ],
      "metadata": {
        "id": "3AKsbJi1CkiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Ensure data is available\n",
        "if 'data' in locals() and hasattr(data, \"empty\") and not data.empty:\n",
        "\n",
        "    # Ensure index is datetime\n",
        "    if not isinstance(data.index, type(pd.to_datetime([]))):\n",
        "        data.index = pd.to_datetime(data.index, errors='coerce')\n",
        "\n",
        "    # Sort by date\n",
        "    data = data.sort_index()\n",
        "\n",
        "    # Required candlestick columns\n",
        "    required_cols = ['1. open', '2. high', '3. low', '4. close']\n",
        "\n",
        "    if all(col in data.columns for col in required_cols):\n",
        "\n",
        "        # Drop rows with missing price data\n",
        "        clean_data = data[required_cols].dropna()\n",
        "\n",
        "        fig = go.Figure(data=[\n",
        "            go.Candlestick(\n",
        "                x=clean_data.index,\n",
        "                open=clean_data['1. open'],\n",
        "                high=clean_data['2. high'],\n",
        "                low=clean_data['3. low'],\n",
        "                close=clean_data['4. close'],\n",
        "                name=f\"{company_name}\"\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=f\"{company_name} ({symbol}) - Candlestick Chart\",\n",
        "            xaxis_title=\"Date\",\n",
        "            yaxis_title=\"Price (USD)\",\n",
        "            xaxis_rangeslider_visible=False,\n",
        "            template=\"plotly_white\",\n",
        "            width=950,\n",
        "            height=550\n",
        "        )\n",
        "\n",
        "        fig.show()\n",
        "\n",
        "    else:\n",
        "        print(\"One or more required OHLC columns are missing from the data.\")\n",
        "else:\n",
        "    print(\"No data available to visualize. Please run the data fetch cell first.\")\n"
      ],
      "metadata": {
        "id": "ReroxWlnCpdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sprint 1 Conclusion\n",
        "**What we achieved in Sprint 1:**\n",
        "\n",
        "1. Collected real-time open-source data from:\n",
        "\n",
        "\n",
        "* Wikipedia (summary)\n",
        "* Yahoo Finance (market prices)\n",
        "* Google News RSS (recent headlines)\n",
        "* Generated synthetic tweets (50) for sentiment analysis\n",
        "\n",
        "2. Cleaned and structured data using **pandas DataFrames**\n",
        "3. Performed sentiment analysis using **TextBlob**\n",
        "\n",
        "4. Visualized key insights:\n",
        "* Sentiment distribution (bar chart)\n",
        "* Sentiment trend across tweets (line chart)\n",
        "* Market price trend (line chart)\n",
        "\n",
        "5. Built a flexible, interactive notebook for any asset/company input\n",
        "\n",
        "This notebook sets the foundation for Sprint 2, where we will integrate real-time dashboards and AI-driven analytics."
      ],
      "metadata": {
        "id": "Gzr2Bm2tMuNE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Slack Alerts Sender**"
      ],
      "metadata": {
        "id": "kSh8Z9qu0Oon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Slack Alert Sender\n",
        "\n",
        "import os, json, requests\n",
        "from datetime import datetime\n",
        "\n",
        "# ‚úÖ Store your real webhook here for local testing\n",
        "# (In Colab use: os.environ[\"SLACK_WEBHOOK_URL\"] = userdata.get(\"SLACK_WEBHOOK_URL\"))\n",
        "SLACK_WEBHOOK_URL = userdata.get(\"SLACK_WEBHOOK_URL\")\n",
        "def send_slack_alert(data):\n",
        "    webhook = SLACK_WEBHOOK_URL\n",
        "    if not webhook:\n",
        "        print(\"‚ùå Slack webhook missing.\")\n",
        "        return\n",
        "\n",
        "    # ‚úÖ Slack requires at least a \"text\" field\n",
        "    payload = {\n",
        "        \"text\": f\"üö® {data['alert_type']} for {data['company_name']} ({data['company_ticker']})\",\n",
        "        \"blocks\": [\n",
        "            {\n",
        "                \"type\": \"header\",\n",
        "                \"text\": {\n",
        "                    \"type\": \"plain_text\",\n",
        "                    \"text\": f\"{data['alert_type']} ‚Äî {data['company_ticker']}\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"section\",\n",
        "                \"fields\": [\n",
        "                    {\"type\": \"mrkdwn\", \"text\": f\"*Company:*\\n{data['company_name']}\"},\n",
        "                    {\"type\": \"mrkdwn\", \"text\": f\"*Ticker:*\\n{data['company_ticker']}\"},\n",
        "                    # {\"type\": \"mrkdwn\", \"text\": f\"*Price:*\\n${data['current_price']:.2f}\"},\n",
        "                    {\"type\": \"mrkdwn\", \"text\": f\"*Sentiment:*\\n{data['sentiment_score']:.2f}\"},\n",
        "                    # {\"type\": \"mrkdwn\", \"text\": f\"*Daily Change:*\\n{data['daily_change_percent']:.2f}%\"},\n",
        "                    {\"type\": \"mrkdwn\", \"text\": f\"*Volatility:*\\n{data['volatility_metric']}\"},\n",
        "                ]\n",
        "            },\n",
        "            {\"type\": \"divider\"},\n",
        "            {\n",
        "                \"type\": \"section\",\n",
        "                \"text\": {\n",
        "                    \"type\": \"mrkdwn\",\n",
        "                    \"text\": f\"*Recommendation:*\\n{data['strategic_action']}\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"type\": \"context\",\n",
        "                \"elements\": [\n",
        "                    {\"type\": \"mrkdwn\", \"text\": f\"Signal Time: {data['signal_time']}\"}\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    r = requests.post(\n",
        "        webhook,\n",
        "        data=json.dumps(payload),\n",
        "        headers={\"Content-Type\": \"application/json\"}\n",
        "    )\n",
        "\n",
        "    if r.status_code == 200:\n",
        "        print(\"‚úÖ Slack alert sent successfully!\")\n",
        "    else:\n",
        "        print(\"‚ùå Slack Error:\", r.text)\n",
        "def build_alert(company, ticker, title, body, sentiment):\n",
        "    return {\n",
        "        \"company_name\": company,\n",
        "        \"company_ticker\": ticker,\n",
        "        \"alert_type\": title,\n",
        "        \"strategic_action\": body,\n",
        "        # \"current_price\": price,\n",
        "        \"sentiment_score\": sentiment,\n",
        "        # \"daily_change_percent\": change,\n",
        "        # \"daily_change_absolute\": round(price * (change / 100), 2),\n",
        "        \"volatility_metric\": \"Medium\",\n",
        "        \"signal_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    }\n"
      ],
      "metadata": {
        "id": "cuVnt1tW0HMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# day_change = ((df.y.iloc[-1] - df.y.iloc[-2]) / df.y.iloc[-2]) * 100\n",
        "sent_df = pd.DataFrame(deep_sentiments)\n",
        "sent_df[\"sentiment\"] = sent_df[\"sentiment\"].str.lower()\n",
        "\n",
        "sentiment_dist = (\n",
        "    sent_df[\"sentiment\"]\n",
        "    .value_counts(normalize=True)\n",
        "    .reindex([\"positive\", \"negative\", \"neutral\"], fill_value=0)\n",
        ")\n",
        "\n",
        "pos_ratio = sentiment_dist[\"positive\"]\n",
        "neg_ratio = sentiment_dist[\"negative\"]\n",
        "neu_ratio = sentiment_dist[\"neutral\"]\n",
        "\n",
        "if pos_ratio > 0.60:\n",
        "    alert = build_alert(\n",
        "        company=company_name,\n",
        "        ticker=symbol,\n",
        "        title=\"üìà Bullish Sentiment Detected\",\n",
        "        body=f\"{company_name} shows strong positive sentiment ({pos_ratio*100:.1f}%).\",\n",
        "        # price=float(df.y.iloc[-1]),\n",
        "        sentiment=float(pos_ratio),\n",
        "        # change=float(day_change)\n",
        "    )\n",
        "    send_slack_alert(alert)\n",
        "elif neg_ratio > 0.60:\n",
        "    alert = build_alert(\n",
        "        company=company_name,\n",
        "        ticker=symbol,\n",
        "        title=\"üìâ Bearish Sentiment Detected\",\n",
        "        body=f\"{company_name} shows strong *negative* sentiment ({neg_ratio*100:.1f}%). \"\n",
        "             f\"Consider risk management or hedging strategies.\",\n",
        "        # price=float(df.y.iloc[-1]),\n",
        "        sentiment=float(-neg_ratio),  # negative for clarity if you want\n",
        "        # change=float(day_change)\n",
        "    )\n",
        "    send_slack_alert(alert)\n",
        "else:\n",
        "    alert = build_alert(\n",
        "        company=company_name,\n",
        "        ticker=symbol,\n",
        "        title=\"‚öñÔ∏è Market Sentiment Neutral\",\n",
        "        body=(\n",
        "            f\"{company_name} shows mixed or neutral sentiment.\\n\\n\"\n",
        "            f\"Positive: {pos_ratio*100:.1f}% | \"\n",
        "            f\"Negative: {neg_ratio*100:.1f}% | \"\n",
        "            f\"Neutral: {neu_ratio*100:.1f}%\\n\\n\"\n",
        "            f\"No strong directional bias detected.\"\n",
        "        ),\n",
        "        sentiment=0.0,\n",
        "    )\n",
        "    send_slack_alert(alert)"
      ],
      "metadata": {
        "id": "zwgOlJi00Ku1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sprint 3: Code Cell - Prophet Forecasting, Signal Generation, and Slack Alerts\n",
        "\n",
        "!pip install -q prophet requests  # Install if needed\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "from prophet.diagnostics import cross_validation, performance_metrics\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from typing import Dict, Any\n",
        "from google.colab import userdata\n",
        "\n",
        "def download_price_data(ticker: str, period: str = '2y') -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Download historical closing prices from Yahoo Finance.\n",
        "\n",
        "    Args:\n",
        "        ticker (str): Stock symbol.\n",
        "        period (str): Data period (e.g., '2y').\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with 'ds' (date) and 'y' (close price) columns.\n",
        "\n",
        "    Error Handling:\n",
        "        - Falls back to mock data if download fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        data = yf.download(ticker, period=period, progress=False)\n",
        "        df = data[['Close']].reset_index()\n",
        "        df.columns = ['ds', 'y']\n",
        "        df['ds'] = pd.to_datetime(df['ds'])\n",
        "        print(f\"Downloaded {len(df)} days of {ticker} price data.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Download error: {e}. Using mock data.\")\n",
        "        dates = pd.date_range(start='2023-12-01', periods=500, freq='D')\n",
        "        mock_prices = 500 + np.cumsum(np.random.randn(500) * 5)\n",
        "        return pd.DataFrame({'ds': dates, 'y': mock_prices})\n",
        "\n",
        "def build_prophet_model(data: pd.DataFrame) -> Prophet:\n",
        "    \"\"\"\n",
        "    Fit Prophet model with seasonality and validate via cross-validation.\n",
        "\n",
        "    Args:\n",
        "        data (pd.DataFrame): Input data with 'ds' and 'y'.\n",
        "\n",
        "    Returns:\n",
        "        Prophet: Fitted model object.\n",
        "    \"\"\"\n",
        "    model = Prophet(\n",
        "        daily_seasonality=True,\n",
        "        weekly_seasonality=True,\n",
        "        yearly_seasonality=True,\n",
        "        changepoint_prior_scale=0.05,\n",
        "        seasonality_prior_scale=10.0\n",
        "    )\n",
        "    model.add_country_holidays(country_name='US')  # Add US holidays\n",
        "    model.fit(data)\n",
        "\n",
        "    # Cross-validation for RMSE\n",
        "    try:\n",
        "        df_cv = cross_validation(model, initial='730 days', period='180 days', horizon='30 days')\n",
        "        df_perf = performance_metrics(df_cv)\n",
        "        rmse = df_perf['rmse'].mean()\n",
        "        print(f\"Model fitted. Cross-validation RMSE: {rmse:.2f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Validation skipped: {e}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def generate_7day_forecast(model: Prophet) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generate 7-day future forecast with confidence intervals.\n",
        "\n",
        "    Args:\n",
        "        model (Prophet): Fitted model.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Forecast DataFrame (ds, yhat, yhat_lower, yhat_upper).\n",
        "    \"\"\"\n",
        "    future = model.make_future_dataframe(periods=7)\n",
        "    forecast = model.predict(future)\n",
        "    forecast_7d = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(7)\n",
        "    forecast_7d['ds'] = forecast_7d['ds'].dt.strftime('%Y-%m-%d')\n",
        "    print(\"7-day forecast generated.\")\n",
        "    return forecast_7d\n",
        "\n",
        "# Main Execution\n",
        "print(\"=== SPRINT 3: FORECASTING & ALERTS ===\\n\")\n",
        "\n",
        "# Step 1: Data\n",
        "price_data = download_price_data(symbol)\n",
        "\n",
        "# Step 2: Model\n",
        "prophet_model = build_prophet_model(price_data)\n",
        "\n",
        "# Step 3: Forecast\n",
        "forecast_df = generate_7day_forecast(prophet_model)\n",
        "\n",
        "\n",
        "# Outputs\n",
        "print(\"\\n--- 7-DAY FORECAST TABLE ---\")\n",
        "print(forecast_df.round(2).to_string(index=False))\n",
        "\n",
        "\n",
        "# Store for Sprint 4\n",
        "%store price_data prophet_model forecast_df"
      ],
      "metadata": {
        "id": "Kve70VY8rkaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# STATIC ANALYTICS DASHBOARD (COLAB)\n",
        "# ==========================================\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# -------- SAFE GLOBALS --------\n",
        "company_name = globals().get(\"company_name\", \"Unknown Asset\")\n",
        "market_df = globals().get(\"market_df\", pd.DataFrame())\n",
        "wiki_summary = globals().get(\"wiki_summary\", \"\")\n",
        "forecast_df = globals().get(\"forecast_df\", pd.DataFrame())\n",
        "deep_sentiments = globals().get(\"deep_sentiments\", [])\n",
        "news_articles_with_links = globals().get(\"news_articles_with_links\", [])\n",
        "alert = globals().get(\"alert\", {})\n",
        "\n",
        "# -------- DASHBOARD STYLE --------\n",
        "display(HTML(\"\"\"\n",
        "<style>\n",
        "body {\n",
        "  background:#05060a;\n",
        "  color:#f5f5f5;\n",
        "  font-family:Segoe UI, system-ui, sans-serif;\n",
        "}\n",
        ".dashboard {\n",
        "  max-width:1150px;\n",
        "  margin:auto;\n",
        "}\n",
        ".card {\n",
        "  background:#0b1020;\n",
        "  border-radius:16px;\n",
        "  padding:16px;\n",
        "  margin-bottom:16px;\n",
        "  box-shadow:0 0 30px rgba(0,0,0,0.6);\n",
        "}\n",
        ".title {\n",
        "  font-size:22px;\n",
        "  font-weight:700;\n",
        "  color:#e9f5ff;\n",
        "}\n",
        ".subtitle {\n",
        "  font-size:13px;\n",
        "  color:#a9c7ff;\n",
        "}\n",
        ".section {\n",
        "  font-size:15px;\n",
        "  font-weight:600;\n",
        "  margin-bottom:6px;\n",
        "  color:#9fdcff;\n",
        "}\n",
        ".small {\n",
        "  font-size:12px;\n",
        "  color:#b8c7e0;\n",
        "}\n",
        "hr {\n",
        "  border:0;\n",
        "  border-top:1px solid #222;\n",
        "  margin:12px 0;\n",
        "}\n",
        "a { color:#7adfff; text-decoration:none; }\n",
        "</style>\n",
        "\"\"\"))\n",
        "\n",
        "# -------- HEADER --------\n",
        "display(HTML(f\"\"\"\n",
        "<div class=\"dashboard\">\n",
        "  <div class=\"card\">\n",
        "    <div class=\"title\">Financial Sentiment & Market Intelligence Dashboard</div>\n",
        "    <div class=\"subtitle\">\n",
        "      Infosys Springboard Internship ¬∑ Static Analytical\n",
        "    </div>\n",
        "    <div style=\"margin-top:6px;\">üìå <b>{company_name}</b></div>\n",
        "  </div>\n",
        "\"\"\"))\n",
        "\n",
        "# -------- OVERVIEW --------\n",
        "summary = wiki_summary[:500] + \"...\" if wiki_summary else \"Company overview unavailable.\"\n",
        "display(HTML(f\"\"\"\n",
        "  <div class=\"card\">\n",
        "    <div class=\"section\">Company Overview</div>\n",
        "    <p class=\"small\">{wiki_summary}</p>\n",
        "    <ul class=\"small\">\n",
        "      <li>Market price & trend analysis</li>\n",
        "      <li>FinBERT-based news sentiment</li>\n",
        "      <li>Prophet forecasting (7-day)</li>\n",
        "      <li>Slack risk alert generation</li>\n",
        "    </ul>\n",
        "  </div>\n",
        "\"\"\"))\n",
        "\n",
        "# -------- MARKET PRICE --------\n",
        "if not market_df.empty:\n",
        "    df = market_df.tail(60).sort_values(\"Date\")\n",
        "    fig_price = px.line(df, x=\"Date\", y=\"Close\", template=\"plotly_dark\")\n",
        "    fig_price.update_traces(line=dict(color=\"#00e5ff\", width=3))\n",
        "    fig_price.update_layout(height=500, title=\"Recent Price Trend\", showlegend=False)\n",
        "    fig_price.show()\n",
        "\n",
        "# -------- SENTIMENT (DISTRIBUTION + POLARITY) --------\n",
        "if deep_sentiments:\n",
        "    s_df = pd.DataFrame(deep_sentiments)\n",
        "    s_df[\"sentiment\"] = s_df[\"sentiment\"].str.capitalize()\n",
        "\n",
        "    # ---- Distribution data ----\n",
        "    counts = s_df[\"sentiment\"].value_counts().reset_index()\n",
        "    counts.columns = [\"sentiment\", \"count\"]\n",
        "\n",
        "    # ---- Polarity data ----\n",
        "    max_points = 10\n",
        "    sentiments = deep_sentiments[:max_points]\n",
        "\n",
        "    x_values = list(range(1, len(sentiments) + 1))\n",
        "    y_values = []\n",
        "\n",
        "    for item in sentiments:\n",
        "        sentiment = item[\"sentiment\"].lower()\n",
        "        confidence = item[\"confidence\"]\n",
        "\n",
        "        if sentiment == \"positive\":\n",
        "            y_values.append(confidence)\n",
        "        elif sentiment == \"negative\":\n",
        "            y_values.append(-confidence)\n",
        "        else:\n",
        "            y_values.append(0)\n",
        "\n",
        "    # ---- Plot ----\n",
        "    plt.style.use(\"dark_background\")\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # Left: Sentiment Distribution\n",
        "    sns.barplot(\n",
        "        data=counts,\n",
        "        x=\"sentiment\",\n",
        "        y=\"count\",\n",
        "        hue=\"sentiment\",\n",
        "        palette={\n",
        "            \"Negative\": \"#ff4c61\",\n",
        "            \"Neutral\": \"#f5d742\",\n",
        "            \"Positive\": \"#00e676\"\n",
        "        },\n",
        "        legend=False,\n",
        "        ax=axes[0]\n",
        "    )\n",
        "    axes[0].set_title(\"News Sentiment Distribution\")\n",
        "    axes[0].set_xlabel(\"Sentiment\")\n",
        "    axes[0].set_ylabel(\"Count\")\n",
        "    axes[0].grid(alpha=0.2)\n",
        "\n",
        "    # Right: Sentiment Polarity\n",
        "    axes[1].plot(x_values, y_values, marker=\"o\")\n",
        "    axes[1].axhline(0, linestyle=\"--\", alpha=0.4)\n",
        "    axes[1].set_title(\"Sentiment Polarity (Sequence)\")\n",
        "    axes[1].set_xlabel(\"Sentiment Order\")\n",
        "    axes[1].set_ylabel(\"Polarity Score\")\n",
        "    axes[1].grid(alpha=0.2)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# -------- FORECAST --------\n",
        "if not forecast_df.empty:\n",
        "    f = forecast_df.tail(7)\n",
        "    fig_fc = go.Figure()\n",
        "    fig_fc.add_trace(go.Scatter(\n",
        "        x=f[\"ds\"], y=f[\"yhat\"],\n",
        "        mode=\"lines+markers\",\n",
        "        name=\"Forecast\",\n",
        "        line=dict(color=\"#ffb347\", width=3)\n",
        "    ))\n",
        "    fig_fc.add_trace(go.Scatter(\n",
        "        x=f[\"ds\"], y=f[\"yhat_upper\"],\n",
        "        line=dict(color=\"rgba(255,179,71,0.3)\", dash=\"dot\"),\n",
        "        showlegend=False\n",
        "    ))\n",
        "    fig_fc.add_trace(go.Scatter(\n",
        "        x=f[\"ds\"], y=f[\"yhat_lower\"],\n",
        "        fill=\"tonexty\",\n",
        "        fillcolor=\"rgba(255,179,71,0.15)\",\n",
        "        showlegend=False\n",
        "    ))\n",
        "    fig_fc.update_layout(\n",
        "        template=\"plotly_dark\",\n",
        "        height=350,\n",
        "        title=\"7-Day Price Forecast (Prophet)\"\n",
        "    )\n",
        "    fig_fc.show()\n",
        "\n",
        "# -------- NEWS --------\n",
        "news_html = \"\"\n",
        "for i, n in enumerate(news_articles_with_links[:5], 1):\n",
        "    news_html += f\"<p class='small'><b>{i}.</b> <a href='{n['link']}' target='_blank'>{n['title']}</a></p>\"\n",
        "\n",
        "display(HTML(f\"\"\"\n",
        "  <div class=\"card\">\n",
        "    <div class=\"section\">Latest News Headlines</div>\n",
        "    {news_html if news_html else \"<p class='small'>No news available.</p>\"}\n",
        "  </div>\n",
        "\"\"\"))\n",
        "\n",
        "# -------- SLACK ALERT --------\n",
        "display(HTML(f\"\"\"\n",
        "  <div class=\"card\">\n",
        "    <div class=\"section\">Generated Slack Alert</div>\n",
        "    <p class=\"small\"><b>Type:</b> {alert.get(\"alert_type\",\"N/A\")}</p>\n",
        "    <p class=\"small\"><b>Signal:</b> {alert.get(\"strategic_action\",\"N/A\")}</p>\n",
        "    <p class=\"small\"><b>Timestamp:</b> {alert.get(\"signal_time\",\"N/A\")}</p>\n",
        "  </div>\n",
        "</div>\n",
        "\"\"\"))\n"
      ],
      "metadata": {
        "id": "_I6dy5Y3lz3S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}